"""
RAG Engine - ä¼ä¸šå“ç‰ŒçŸ¥è¯†æ£€ç´¢æ¨¡å—

åŸºäº RAG (Retrieval-Augmented Generation) çš„å“ç‰ŒçŸ¥è¯†åº“æ£€ç´¢ç³»ç»Ÿã€‚
ç”¨äºæ£€ç´¢ä¼ä¸šå“ç‰Œæ‰‹å†Œï¼Œè¾…åŠ© AI ç”Ÿæˆç¬¦åˆå“ç‰Œè§„èŒƒçš„æµ·æŠ¥è®¾è®¡ã€‚

é»˜è®¤å“ç‰Œæ•°æ®ä» data/default_brand_knowledge.json åŠ è½½ã€‚

æŠ€æœ¯æ ˆï¼š
    - è½»é‡çº§ç‰ˆæœ¬: sentence-transformers + cosine similarity
    - å®Œæ•´ç‰ˆæœ¬: langchain + chromadb (å¯é€‰å‡çº§)

Author: VibePoster Team
Date: 2025-01
"""

import json
import os
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from pathlib import Path

import numpy as np

from ...core.interfaces import IKnowledgeBase
from ...core.logger import get_logger

logger = get_logger(__name__)

# æ•°æ®æ–‡ä»¶è·¯å¾„
DATA_DIR = Path(__file__).parent.parent / "data"
DEFAULT_BRAND_FILE = DATA_DIR / "default_brand_knowledge.json"

# å°è¯•å¯¼å…¥ sentence-transformersï¼ˆè½»é‡çº§æ–¹æ¡ˆï¼‰
try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    logger.warning("sentence-transformers æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€å•æ–‡æœ¬åŒ¹é…")

# å°è¯•å¯¼å…¥ chromadbï¼ˆå®Œæ•´æ–¹æ¡ˆï¼‰
try:
    import chromadb
    from chromadb.config import Settings as ChromaSettings
    CHROMADB_AVAILABLE = True
except ImportError:
    CHROMADB_AVAILABLE = False


@dataclass
class Document:
    """æ–‡æ¡£æ•°æ®ç»“æ„"""
    id: str
    text: str
    metadata: Dict[str, Any]
    embedding: Optional[np.ndarray] = None


class BrandKnowledgeBase(IKnowledgeBase):
    """
    å“ç‰ŒçŸ¥è¯†åº“ç±»
    
    å®ç° IKnowledgeBase æ¥å£ã€‚
    
    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. è½»é‡çº§æ¨¡å¼ï¼šä½¿ç”¨ sentence-transformers è¿›è¡Œå‘é‡æ£€ç´¢
    2. ç®€å•æ¨¡å¼ï¼šä½¿ç”¨å…³é”®è¯åŒ¹é…ï¼ˆå½“ä¾èµ–åº“ä¸å¯ç”¨æ—¶ï¼‰
    """
    
    def __init__(
        self,
        use_chromadb: Optional[bool] = None,
        persist_directory: Optional[str] = None,
        load_default_data: Optional[bool] = None,
        embedding_model: Optional[str] = None,
        default_data_file: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–å“ç‰ŒçŸ¥è¯†åº“
        
        Args:
            use_chromadb: æ˜¯å¦ä½¿ç”¨ chromadbï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
            persist_directory: ChromaDB æŒä¹…åŒ–ç›®å½•ï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
            load_default_data: æ˜¯å¦åŠ è½½é»˜è®¤æ•°æ®ï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
            embedding_model: åµŒå…¥æ¨¡å‹åç§°ï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
            default_data_file: é»˜è®¤å“ç‰Œæ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        # ä»é…ç½®è¯»å–é»˜è®¤å€¼
        from ...core.config import settings
        
        self.use_chromadb = use_chromadb if use_chromadb is not None else settings.rag.USE_CHROMADB
        self.persist_directory = persist_directory or settings.rag.PERSIST_DIRECTORY
        self.load_default = load_default_data if load_default_data is not None else settings.rag.LOAD_DEFAULT_DATA
        self.embedding_model_name = embedding_model or settings.rag.EMBEDDING_MODEL
        self.default_data_file = Path(default_data_file) if default_data_file else DEFAULT_BRAND_FILE
        
        self.documents: List[Document] = []
        self.use_chromadb = self.use_chromadb and CHROMADB_AVAILABLE
        self.model = None
        
        # åˆå§‹åŒ–å‘é‡æ¨¡å‹
        if SENTENCE_TRANSFORMERS_AVAILABLE and not self.use_chromadb:
            logger.info("ä½¿ç”¨ sentence-transformers è¿›è¡Œå‘é‡æ£€ç´¢")
            self.model = SentenceTransformer(self.embedding_model_name)
        elif self.use_chromadb:
            logger.info("ä½¿ç”¨ chromadb è¿›è¡Œå‘é‡æ£€ç´¢")
            os.makedirs(self.persist_directory, exist_ok=True)
            self.client = chromadb.Client(ChromaSettings(
                chroma_db_impl="duckdb+parquet",
                persist_directory=self.persist_directory
            ))
            self.collection = self.client.get_or_create_collection(
                name="brand_knowledge",
                metadata={"hnsw:space": "cosine"}
            )
        else:
            logger.warning("ä½¿ç”¨ç®€å•å…³é”®è¯åŒ¹é…ï¼ˆæ€§èƒ½è¾ƒä½ï¼‰")
        
        # åŠ è½½é»˜è®¤å“ç‰Œæ•°æ®
        if self.load_default:
            self._load_default_data()
    
    def _load_default_data(self):
        """ä» JSON æ–‡ä»¶åŠ è½½é»˜è®¤çš„å“ç‰Œæ‰‹å†Œæ•°æ®"""
        if not self.default_data_file.exists():
            logger.warning(f"é»˜è®¤å“ç‰Œæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.default_data_file}")
            return
        
        try:
            with open(self.default_data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            brands = data.get("brands", [])
            
            for doc in brands:
                self.add_document(
                    text=doc["text"],
                    metadata=doc.get("metadata", {}),
                    doc_id=doc.get("id", f"default_{len(self.documents)}")
                )
            
            logger.info(f"å·²åŠ è½½ {len(brands)} æ¡é»˜è®¤å“ç‰ŒçŸ¥è¯†: {self.default_data_file}")
        
        except Exception as e:
            logger.error(f"åŠ è½½é»˜è®¤å“ç‰Œæ•°æ®å¤±è´¥: {e}")
    
    def add_document(
        self,
        text: str,
        metadata: Optional[Dict[str, Any]] = None,
        doc_id: Optional[str] = None
    ) -> str:
        """
        æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“
        
        Args:
            text: æ–‡æ¡£æ–‡æœ¬å†…å®¹
            metadata: æ–‡æ¡£å…ƒæ•°æ®
            doc_id: æ–‡æ¡£ IDï¼ˆå¯é€‰ï¼‰
        
        Returns:
            æ–‡æ¡£ ID
        """
        if doc_id is None:
            doc_id = f"doc_{len(self.documents)}"
        
        if metadata is None:
            metadata = {}
        
        # è®¡ç®—å‘é‡åµŒå…¥
        embedding = None
        if self.model is not None:
            embedding = self.model.encode(text, convert_to_numpy=True)
        
        # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
        doc = Document(
            id=doc_id,
            text=text,
            metadata=metadata,
            embedding=embedding
        )
        
        # å­˜å‚¨æ–‡æ¡£
        if self.use_chromadb:
            self.collection.add(
                ids=[doc_id],
                documents=[text],
                metadatas=[metadata],
                embeddings=[embedding.tolist()] if embedding is not None else None
            )
        else:
            self.documents.append(doc)
        
        return doc_id
    
    def search(
        self,
        query: str,
        top_k: int = 2,
        filter_metadata: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """
        æ£€ç´¢çŸ¥è¯†åº“
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›å‰ k ä¸ªç»“æœ
            filter_metadata: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        if self.use_chromadb:
            return self._search_chromadb(query, top_k, filter_metadata)
        elif self.model is not None:
            return self._search_vector(query, top_k, filter_metadata)
        else:
            return self._search_keyword(query, top_k, filter_metadata)
    
    def _search_vector(
        self,
        query: str,
        top_k: int,
        filter_metadata: Optional[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """å‘é‡æ£€ç´¢ï¼ˆsentence-transformersï¼‰"""
        query_embedding = self.model.encode(query, convert_to_numpy=True)
        
        scores = []
        for doc in self.documents:
            if filter_metadata and not self._match_metadata(doc.metadata, filter_metadata):
                continue
            
            if doc.embedding is not None:
                similarity = np.dot(query_embedding, doc.embedding) / (
                    np.linalg.norm(query_embedding) * np.linalg.norm(doc.embedding)
                )
                scores.append((doc, similarity))
        
        scores.sort(key=lambda x: x[1], reverse=True)
        
        results = []
        for doc, score in scores[:top_k]:
            results.append({
                "text": doc.text,
                "metadata": doc.metadata,
                "score": float(score)
            })
        
        return results
    
    def _search_keyword(
        self,
        query: str,
        top_k: int,
        filter_metadata: Optional[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """å…³é”®è¯åŒ¹é…æ£€ç´¢ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        scores = []
        query_lower = query.lower()
        
        for doc in self.documents:
            if filter_metadata and not self._match_metadata(doc.metadata, filter_metadata):
                continue
            
            text_lower = doc.text.lower()
            match_score = 0
            for word in query_lower.split():
                if len(word) > 1:
                    match_score += text_lower.count(word)
            
            if match_score > 0:
                scores.append((doc, match_score))
        
        scores.sort(key=lambda x: x[1], reverse=True)
        
        results = []
        for doc, score in scores[:top_k]:
            results.append({
                "text": doc.text,
                "metadata": doc.metadata,
                "score": float(score)
            })
        
        return results
    
    def _search_chromadb(
        self,
        query: str,
        top_k: int,
        filter_metadata: Optional[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ChromaDB æ£€ç´¢"""
        results = self.collection.query(
            query_texts=[query],
            n_results=top_k,
            where=filter_metadata
        )
        
        formatted_results = []
        if results['documents']:
            for i, doc in enumerate(results['documents'][0]):
                formatted_results.append({
                    "text": doc,
                    "metadata": results['metadatas'][0][i] if results['metadatas'] else {},
                    "score": 1.0 - results['distances'][0][i] if results['distances'] else 0.0
                })
        
        return formatted_results
    
    def _match_metadata(
        self,
        doc_metadata: Dict[str, Any],
        filter_metadata: Dict[str, Any]
    ) -> bool:
        """æ£€æŸ¥æ–‡æ¡£å…ƒæ•°æ®æ˜¯å¦åŒ¹é…è¿‡æ»¤æ¡ä»¶"""
        for key, value in filter_metadata.items():
            if key not in doc_metadata or doc_metadata[key] != value:
                return False
        return True
    
    def get_all_documents(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰æ–‡æ¡£ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        return [
            {
                "id": doc.id,
                "text": doc.text,
                "metadata": doc.metadata
            }
            for doc in self.documents
        ]
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_documents": len(self.documents),
            "backend": "chromadb" if self.use_chromadb else (
                "sentence-transformers" if self.model else "keyword"
            ),
            "model_available": SENTENCE_TRANSFORMERS_AVAILABLE,
            "chromadb_available": CHROMADB_AVAILABLE,
            "embedding_model": self.embedding_model_name if self.model else None,
            "default_data_file": str(self.default_data_file)
        }


# ============================================================================
# å•å…ƒæµ‹è¯•
# ============================================================================

if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO)
    
    print("=" * 80)
    print("RAG Engine - å“ç‰ŒçŸ¥è¯†æ£€ç´¢æµ‹è¯•")
    print("=" * 80)
    
    # åˆå§‹åŒ–çŸ¥è¯†åº“
    rag = BrandKnowledgeBase()
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡:")
    stats = rag.get_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # æµ‹è¯•æ£€ç´¢
    print("\n" + "=" * 80)
    print("[æµ‹è¯•] æŸ¥è¯¢: 'åä¸ºçš„é…è‰²'")
    print("=" * 80)
    results = rag.search("åä¸ºçš„é…è‰²", top_k=2)
    for i, result in enumerate(results, 1):
        print(f"\nç»“æœ {i} (ç›¸ä¼¼åº¦: {result['score']:.4f}):")
        print(f"  æ–‡æœ¬: {result['text'][:80]}...")
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")


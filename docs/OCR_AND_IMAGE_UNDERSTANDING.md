# OCR ä¸å›¾åƒç†è§£

> **ç»Ÿä¸€æ–‡æ¡£** - åˆå¹¶äº†è®¾è®¡ã€å®ç°ã€ä¼˜åŒ–ä¸‰ä¸ªæ–¹é¢çš„å†…å®¹

---

## ğŸ“‹ ç›®å½•

1. [è®¾è®¡æ¦‚è¿°](#è®¾è®¡æ¦‚è¿°)
2. [æŠ€æœ¯å®ç°](#æŠ€æœ¯å®ç°)
3. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
4. [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)

---

## è®¾è®¡æ¦‚è¿°

### 1.1 åŠŸèƒ½å®šä½

**OCR + å›¾åƒç†è§£** æ˜¯ Visual Agent çš„æ ¸å¿ƒèƒ½åŠ›ï¼Œç”¨äºï¼š
- æå–å›¾ç‰‡ä¸­çš„æ–‡å­—ä¿¡æ¯ï¼ˆOCRï¼‰
- ç†è§£å›¾ç‰‡çš„é£æ ¼ã€é…è‰²ã€ä¸»é¢˜ï¼ˆå›¾åƒç†è§£ï¼‰
- ä¸ºæµ·æŠ¥è®¾è®¡æä¾›ä¼˜åŒ–å»ºè®®

### 1.2 åº”ç”¨åœºæ™¯

#### åœºæ™¯ Aï¼šç”¨æˆ·ä¸Šä¼ å‚è€ƒå›¾ç‰‡
```
ç”¨æˆ·: "å‚è€ƒè¿™å¼ å›¾ç‰‡çš„é£æ ¼åšä¸€å¼ æ‹›è˜æµ·æŠ¥"
     â†“
Visual Agent:
  1. OCR è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­— â†’ æå–æ ‡é¢˜å€™é€‰
  2. å›¾åƒç†è§£åˆ†æé£æ ¼ â†’ æå–é…è‰²æ–¹æ¡ˆã€é£æ ¼å…³é”®è¯
  3. ç”Ÿæˆå»ºè®® â†’ ä¼˜åŒ–è®¾è®¡ç®€æŠ¥
```

#### åœºæ™¯ Bï¼šç”¨æˆ·ä¸Šä¼ èƒŒæ™¯å›¾
```
ç”¨æˆ·: ä¸Šä¼ ä¸€å¼ å…¬å¸ç…§ç‰‡ä½œä¸ºèƒŒæ™¯
     â†“
Visual Agent:
  1. OCR è¯†åˆ«ï¼ˆå¦‚ï¼šå…¬å¸åç§°ã€æ ‡è¯­ï¼‰
  2. å›¾åƒç†è§£ â†’ åˆ†æä¸»è‰²è°ƒã€æä¾›æ–‡å­—é¢œè‰²å»ºè®®
  3. å¸ƒå±€å»ºè®® â†’ å»ºè®®æ–‡å­—æ”¾åœ¨ç©ºç™½åŒºåŸŸ
```

### 1.3 è¾“å…¥è¾“å‡º

**è¾“å…¥**ï¼š
- `image_data`: å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®
- `user_prompt`: ç”¨æˆ·éœ€æ±‚æè¿°ï¼ˆå¯é€‰ï¼‰

**è¾“å‡º**ï¼š
```python
{
    "ocr": {
        "texts": [
            {
                "content": "æ–‡å­—å†…å®¹",
                "position": "ä½ç½®æè¿°",
                "size": "å¤§å°æè¿°",
                "confidence": "é«˜/ä¸­/ä½"
            }
        ],
        "has_text": true
    },
    "understanding": {
        "style": "business",           # é£æ ¼ç±»å‹
        "main_color": "#1E3A8A",       # ä¸»è‰²è°ƒ
        "color_palette": [...],         # é…è‰²æ–¹æ¡ˆ
        "elements": [...],              # å›¾ç‰‡å…ƒç´ 
        "theme": "æ‹›è˜",                # ä¸»é¢˜
        "mood": "æ­£å¼",                 # æƒ…æ„Ÿ
        "layout_hints": {
            "text_position": "top",
            "text_color_suggestion": "#FFFFFF"
        },
        "description": "ä¸€å¼ æ·±è“è‰²å•†åŠ¡é£æ ¼çš„æ‹›è˜æµ·æŠ¥"
    },
    "suggestions": {
        "title_candidates": [...],      # æ ‡é¢˜å€™é€‰
        "style_keywords": [...],        # é£æ ¼å…³é”®è¯
        "color_scheme": {...},          # é…è‰²å»ºè®®
        "font_style": "ç°ä»£ã€ç®€æ´"      # å­—ä½“é£æ ¼å»ºè®®
    }
}
```

---

## æŠ€æœ¯å®ç°

### 2.1 æ ¸å¿ƒæŠ€æœ¯é€‰å‹

#### æ–¹æ¡ˆï¼šDeepSeek Vision API
- âœ… æ”¯æŒ OCR å’Œå›¾åƒç†è§£
- âœ… ä¸€æ¬¡è°ƒç”¨å®Œæˆä¸¤ä¸ªä»»åŠ¡ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
- âœ… å‡†ç¡®ç‡é«˜ï¼Œæ”¯æŒä¸­è‹±æ–‡

### 2.2 å…³é”®ä»£ç 

#### ç»Ÿä¸€æ¥å£
```python
# tools/image_understanding.py

def understand_image(
    image_data: bytes,
    user_prompt: Optional[str] = None
) -> Dict[str, Any]:
    """
    ç†è§£å›¾ç‰‡ï¼ˆç»Ÿä¸€æ¥å£ï¼ŒåŒ…å« OCR + å›¾åƒç†è§£ï¼‰
    
    âš¡ï¸ ä¼˜åŒ–ï¼šä¸€æ¬¡ LLM è°ƒç”¨åŒæ—¶å®Œæˆ OCR å’Œå›¾åƒç†è§£
    """
    # ä¸€æ¬¡ API è°ƒç”¨å®Œæˆ OCR + å›¾åƒç†è§£
    analysis_result = analyze_image_with_llm(image_data, user_prompt)
    
    # æå–ç»“æœ
    ocr_result = analysis_result.get("ocr", {...})
    understanding_result = analysis_result.get("understanding", {...})
    
    # ç”Ÿæˆå»ºè®®
    suggestions = generate_suggestions(ocr_result, understanding_result)
    
    return {
        "ocr": ocr_result,
        "understanding": understanding_result,
        "suggestions": suggestions
    }
```

#### æ ¸å¿ƒå®ç°
```python
def analyze_image_with_llm(
    image_data: bytes,
    user_prompt: Optional[str] = None
) -> Dict[str, Any]:
    """
    ä½¿ç”¨ LLM Vision API åˆ†æå›¾ç‰‡ï¼ˆOCR + å›¾åƒç†è§£ï¼Œä¸€æ¬¡è°ƒç”¨å®Œæˆï¼‰
    """
    client = LLMClientFactory.get_client(provider="deepseek", ...)
    
    # å°†å›¾ç‰‡è½¬æ¢ä¸º base64
    image_base64 = base64.b64encode(image_data).decode('utf-8')
    
    # ä½¿ç”¨ç»Ÿä¸€çš„ Prompt æ¨¡æ¿
    prompt = IMAGE_ANALYSIS_PROMPT_TEMPLATE.format(
        user_prompt=user_prompt if user_prompt else "æ— "
    )
    
    # ä¸€æ¬¡ API è°ƒç”¨
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[{
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {
                    "url": f"data:image/jpeg;base64,{image_base64}"
                }}
            ]
        }],
        temperature=0.2,
    )
    
    content = response.choices[0].message.content
    result = parse_llm_json_response(content, fallback=..., context="å›¾åƒåˆ†æ")
    
    return result
```

### 2.3 Prompt è®¾è®¡

ä½¿ç”¨ç»Ÿä¸€çš„ `IMAGE_ANALYSIS_PROMPT_TEMPLATE`ï¼š

```python
# prompts/templates.py

IMAGE_ANALYSIS_PROMPT_TEMPLATE = """
è¯·åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œæå–ä»¥ä¸‹ä¿¡æ¯ï¼š

## ğŸ“ 1. OCR æ–‡å­—è¯†åˆ«
è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰€æœ‰å¯è§æ–‡å­—...

## ğŸ¨ 2. å›¾åƒç†è§£
### 2.1 é£æ ¼è¯†åˆ«
### 2.2 é…è‰²åˆ†æ
### 2.3 å…ƒç´ è¯†åˆ«
### 2.4 ä¸»é¢˜å’Œæƒ…æ„Ÿ
### 2.5 å¸ƒå±€å»ºè®®
### 2.6 æè¿°

---

**ç”¨æˆ·éœ€æ±‚**: {user_prompt}

---

## è¾“å‡ºæ ¼å¼

{{
    "ocr": {...},
    "understanding": {...}
}}
"""
```

---

## æ€§èƒ½ä¼˜åŒ–

### 3.1 é—®é¢˜èƒŒæ™¯

**ä¹‹å‰çš„å®ç°**ï¼šåˆ†å¼€è°ƒç”¨ OCR å’Œå›¾åƒç†è§£

```python
# âŒ æ—§å®ç°ï¼ˆä½æ•ˆï¼‰
ocr_result = extract_text_with_ocr(image_data)  # ç¬¬ä¸€æ¬¡ API è°ƒç”¨
understanding_result = understand_image_with_llm(image_data, user_prompt)  # ç¬¬äºŒæ¬¡ API è°ƒç”¨
```

**é—®é¢˜**ï¼š
- âŒ åŒä¸€å¼ å›¾ç‰‡å‘é€äº† **2 æ¬¡**
- âŒ æ¶ˆè€— **åŒå€ token**ï¼ˆçº¦ 2000 tokensï¼‰
- âŒ å¢åŠ  **2 å€å»¶è¿Ÿ**ï¼ˆ4-6 ç§’ï¼‰
- âŒ æµªè´¹èµ„æºå’Œæˆæœ¬

### 3.2 ä¼˜åŒ–æ–¹æ¡ˆ

**åˆå¹¶ä¸ºä¸€æ¬¡è°ƒç”¨**ï¼š

```python
# âœ… æ–°å®ç°ï¼ˆé«˜æ•ˆï¼‰
result = analyze_image_with_llm(image_data, user_prompt)  # ä¸€æ¬¡ API è°ƒç”¨

# result åŒ…å«ï¼š
# - ocr: {texts: [...], has_text: true}
# - understanding: {style: "business", ...}
```

### 3.3 æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| **API è°ƒç”¨æ¬¡æ•°** | 2 æ¬¡ | 1 æ¬¡ | **â†“ 50%** |
| **Token æ¶ˆè€—** | ~2000 | ~1250 | **â†“ 37.5%** |
| **å“åº”æ—¶é—´** | 4-6ç§’ | 2-3ç§’ | **â†“ 50%** |
| **æˆæœ¬** | $0.002 | $0.001 | **â†“ 50%** |

### 3.4 ä¼˜åŒ–åŸç†

**Vision LLM çš„å¤šä»»åŠ¡èƒ½åŠ›**ï¼š
- ç°ä»£ Vision LLMï¼ˆå¦‚ DeepSeek Visionï¼‰å…·å¤‡åŒæ—¶å¤„ç†å¤šä¸ªè§†è§‰ä»»åŠ¡çš„èƒ½åŠ›
- OCR å’Œå›¾åƒç†è§£æœ¬è´¨ä¸Šéƒ½æ˜¯å¯¹åŒä¸€å¼ å›¾ç‰‡çš„åˆ†æ
- åˆ†å¼€è°ƒç”¨æ˜¯æµªè´¹èµ„æºï¼Œåˆå¹¶è°ƒç”¨æ˜¯å……åˆ†åˆ©ç”¨ LLM èƒ½åŠ›

**è®¾è®¡åŸåˆ™**ï¼š
- **DRYï¼ˆDon't Repeat Yourselfï¼‰** - é¿å…é‡å¤å‘é€å›¾ç‰‡
- **èµ„æºä¼˜åŒ–** - å……åˆ†åˆ©ç”¨ LLM çš„å¤šä»»åŠ¡èƒ½åŠ›
- **ç”¨æˆ·ä½“éªŒä¼˜å…ˆ** - å‡å°‘ç­‰å¾…æ—¶é—´

---

## ä½¿ç”¨æŒ‡å—

### 4.1 åŸºæœ¬ä½¿ç”¨

```python
from app.tools.image_understanding import understand_image

# åˆ†æå›¾ç‰‡
result = understand_image(
    image_data=image_bytes,
    user_prompt="è®¾è®¡ä¸€å¼ æ‹›è˜æµ·æŠ¥"
)

# æå–ç»“æœ
ocr_texts = result["ocr"]["texts"]
style = result["understanding"]["style"]
suggestions = result["suggestions"]

print(f"è¯†åˆ«æ–‡å­—: {ocr_texts}")
print(f"é£æ ¼: {style}")
print(f"æ ‡é¢˜å€™é€‰: {suggestions['title_candidates']}")
```

### 4.2 åœ¨ Visual Agent ä¸­ä½¿ç”¨

```python
# agents/visual.py

def run_visual_agent(user_images, design_brief):
    """è¿è¡Œ Visual Agentï¼ˆåŒ…å« OCR + å›¾åƒç†è§£ï¼‰"""
    
    image_analyses = []
    
    # åˆ†æç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡
    for img in user_images:
        image_data = img.get("data")
        user_prompt = design_brief.get("user_prompt", "")
        
        # OCR + å›¾åƒç†è§£ï¼ˆä¸€æ¬¡è°ƒç”¨å®Œæˆï¼‰
        analysis_result = understand_image(
            image_data=image_data,
            user_prompt=user_prompt
        )
        
        # ä¿å­˜åˆ†æç»“æœ
        img["ocr"] = analysis_result.get("ocr", {})
        img["understanding"] = analysis_result.get("understanding", {})
        img["suggestions"] = analysis_result.get("suggestions", {})
        
        image_analyses.append(analysis_result)
    
    # ä½¿ç”¨åˆ†æç»“æœä¼˜åŒ–è®¾è®¡ç®€æŠ¥
    all_title_candidates = []
    all_style_keywords = []
    
    for analysis in image_analyses:
        suggestions = analysis.get("suggestions", {})
        all_title_candidates.extend(suggestions.get("title_candidates", []))
        all_style_keywords.extend(suggestions.get("style_keywords", []))
    
    # å¦‚æœ OCR è¯†åˆ«å‡ºæ ‡é¢˜ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå€™é€‰
    if all_title_candidates and not design_brief.get("title"):
        design_brief["title"] = all_title_candidates[0]
    
    # åˆå¹¶é£æ ¼å…³é”®è¯
    if all_style_keywords:
        existing_keywords = design_brief.get("style_keywords", [])
        combined_keywords = list(set(existing_keywords + all_style_keywords))
        design_brief["style_keywords"] = combined_keywords[:5]
    
    # ... ç»§ç»­å¤„ç†
```

### 4.3 é”™è¯¯å¤„ç†

```python
try:
    result = understand_image(image_data, user_prompt)
    
    if result["ocr"].get("error"):
        logger.warning(f"OCR è¯†åˆ«å¤±è´¥: {result['ocr']['error']}")
        # ä½¿ç”¨é»˜è®¤å€¼æˆ–æç¤ºç”¨æˆ·
    
    if result["understanding"].get("error"):
        logger.warning(f"å›¾åƒç†è§£å¤±è´¥: {result['understanding']['error']}")
        # ä½¿ç”¨é»˜è®¤å€¼
        
except Exception as e:
    logger.error(f"å›¾åƒåˆ†æå¤±è´¥: {e}")
    # è¿”å›é”™è¯¯æˆ–ä½¿ç”¨å›é€€æ–¹æ¡ˆ
```

### 4.4 æœ€ä½³å®è·µ

#### âœ… æ¨èåšæ³•

1. **ä½¿ç”¨ç»Ÿä¸€æ¥å£**
   ```python
   # âœ… æ¨è
   result = understand_image(image_data, user_prompt)
   ```

2. **æä¾›ç”¨æˆ·éœ€æ±‚ä¸Šä¸‹æ–‡**
   ```python
   # âœ… æä¾›ä¸Šä¸‹æ–‡ï¼Œæé«˜å‡†ç¡®æ€§
   result = understand_image(
       image_data=image_bytes,
       user_prompt="è®¾è®¡ä¸€å¼ ç§‘æŠ€é£æ ¼çš„äº§å“å‘å¸ƒæµ·æŠ¥"
   )
   ```

3. **å¤„ç†å›é€€æƒ…å†µ**
   ```python
   # âœ… æ£€æŸ¥ç»“æœå¹¶æä¾›é»˜è®¤å€¼
   ocr_result = result.get("ocr", {"texts": [], "has_text": False})
   ```

#### âŒ ä¸æ¨èåšæ³•

1. **å•ç‹¬è°ƒç”¨ OCR**
   ```python
   # âŒ ä¸æ¨èï¼šæµªè´¹èµ„æº
   from app.tools.ocr import extract_text_with_ocr
   ocr_result = extract_text_with_ocr(image_data)
   ```

2. **å¿½ç•¥é”™è¯¯**
   ```python
   # âŒ ä¸æ¨èï¼šæ²¡æœ‰é”™è¯¯å¤„ç†
   result = understand_image(image_data)
   title = result["suggestions"]["title_candidates"][0]  # å¯èƒ½æŠ¥é”™
   ```

---

## ğŸ” æŠ€æœ¯ç»†èŠ‚

### ä¾èµ–æ¨¡å—

```python
# æ ¸å¿ƒä¾èµ–
from ..core.llm import LLMClientFactory          # LLM å®¢æˆ·ç«¯å·¥å‚
from ..core.config import settings               # é…ç½®ç®¡ç†
from ..core.logger import get_logger             # æ—¥å¿—ç³»ç»Ÿ
from ..prompts.templates import IMAGE_ANALYSIS_PROMPT_TEMPLATE  # Prompt æ¨¡æ¿
from ..utils.json_parser import parse_llm_json_response  # JSON è§£æå·¥å…·
```

### é…ç½®é¡¹

```python
# core/config.py

class VisualAgentConfig(BaseSettings):
    """Visual Agent é…ç½®"""
    API_KEY: str = Field(..., env="DEEPSEEK_API_KEY")
    BASE_URL: str = Field(..., env="DEEPSEEK_BASE_URL")
    MODEL: str = "deepseek-chat"
    TEMPERATURE: float = 0.2  # è¾ƒä½æ¸©åº¦ï¼Œç¡®ä¿å‡†ç¡®æ€§
```

### æ—¥å¿—è¾“å‡º

```
ğŸ” å¼€å§‹å›¾åƒåˆ†æï¼ˆOCR + å›¾åƒç†è§£ï¼Œä¸€æ¬¡è°ƒç”¨ï¼‰...
âœ… å›¾åƒåˆ†æå®Œæˆ: é£æ ¼=business, è¯†åˆ«æ–‡å­—æ•°=3
```

---

## ğŸ“Š æ€»ç»“

### æ ¸å¿ƒä¼˜åŠ¿

1. **âœ… æ€§èƒ½ä¼˜åŒ–**ï¼šä¸€æ¬¡è°ƒç”¨å®Œæˆä¸¤ä¸ªä»»åŠ¡ï¼Œé€Ÿåº¦æå‡ 50%
2. **âœ… æˆæœ¬é™ä½**ï¼šToken æ¶ˆè€—å‡å°‘ 37.5%
3. **âœ… ä»£ç ç®€æ´**ï¼šç»Ÿä¸€æ¥å£ï¼Œæ˜“äºä½¿ç”¨
4. **âœ… å‡†ç¡®åº¦é«˜**ï¼šDeepSeek Vision APIï¼Œæ”¯æŒä¸­è‹±æ–‡

### é€‚ç”¨åœºæ™¯

- âœ… ç”¨æˆ·ä¸Šä¼ å‚è€ƒå›¾ç‰‡
- âœ… ç”¨æˆ·ä¸Šä¼ èƒŒæ™¯å›¾
- âœ… åˆ†æå›¾ç‰‡é£æ ¼å’Œé…è‰²
- âœ… æå–å›¾ç‰‡ä¸­çš„æ–‡å­—

### æœªæ¥ä¼˜åŒ–

1. **æ‰¹é‡åˆ†æ**ï¼šæ”¯æŒä¸€æ¬¡åˆ†æå¤šå¼ å›¾ç‰‡
2. **ç¼“å­˜æœºåˆ¶**ï¼šå¯¹ç›¸åŒå›¾ç‰‡å¤ç”¨åˆ†æç»“æœ
3. **æµå¼è¿”å›**ï¼šæ”¯æŒ streamingï¼Œå…ˆè¿”å› OCR å†è¿”å›ç†è§£ç»“æœ
4. **æ›´å¤š LLM æ”¯æŒ**ï¼šæ”¯æŒ GPT-4Vã€Gemini Vision ç­‰

---

**æœ€åæ›´æ–°**: 2025-01-01

